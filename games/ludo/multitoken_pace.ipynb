{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "os.chdir(\"/Users/Pace/Documents/Education/Universität Potsdam/Semester 4 - Summer 2024/Evaluating Chatp-Optimized Language Models/Project\")\n",
    "from backends import ModelSpec, Model, get_model_for, load_model_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, llm: Model, system_prompt: str, instructions: str) -> None:\n",
    "        self.llm: Model = llm\n",
    "\n",
    "        # Prompt and response attributes\n",
    "        self.system_prompt: str = system_prompt\n",
    "        self.instructions: str = instructions\n",
    "        self.last_response: list = []\n",
    "        self.context: list = []\n",
    "        self.reprompt: bool = False\n",
    "        self.tag: str = \"MY MOVE:\"\n",
    "        self.sign: str = \" -> \"\n",
    "        self.separator: str = \" ; \"\n",
    "\n",
    "        # Constructs board with n fields\n",
    "        self.n_fields: int = 23\n",
    "        cells: list = []\n",
    "        for _ in range(self.n_fields):\n",
    "            cells.append(\"□\")\n",
    "        self.board = \" \".join(cells).rstrip()\n",
    "        self.current_state: str = self.board\n",
    "\n",
    "        self.rolls: list = [6, 5, 4, 5, 6, 6, 2, 3, 6, 5, 1, 2, 5, 3, 4]\n",
    "        self.turn: int = 0\n",
    "\n",
    "        # Token attributes\n",
    "        self.tokens_inplay: dict = {\"X\": False, \"Y\": False}\n",
    "        self.current_position: dict = {\"X\": 0, \"Y\": 0}\n",
    "        self.six_count: int = 0\n",
    "\n",
    "    def make_move(self, reprompt_message: str | None = None) -> None:\n",
    "        # Prepares the appropriate message for the current turn\n",
    "        match self.turn:\n",
    "            case 0:\n",
    "                print(f\"TURN 0: {self.board}\")\n",
    "                message: str = f\"{self.instructions}\\nAre you ready to play?\\nBeginning state: {self.board}\\nTurn number: {self.turn}, Roll: {self.rolls[self.turn]}. Where will you move your token? Let's think step by step.\"\n",
    "\n",
    "            case _:\n",
    "                message: str = f\"Current state: {self.current_state}\\nNext turn number: {self.turn}, Roll: {self.rolls[self.turn]}. Where will you move your token? Let's think step by step.\"\n",
    "                message = reprompt_message + message if reprompt_message else message\n",
    "\n",
    "        # Delivers the message, then retrieves the response\n",
    "        self._add_message(message)\n",
    "        _, _, response_text = self.llm.generate_response(self.context)\n",
    "\n",
    "        # Parses and saves the response\n",
    "        move: dict = self._parse_reply(response_text)\n",
    "        self.last_response = response_text\n",
    "\n",
    "        # If the move is valid, updates everything accordingly\n",
    "        if self._check_move(move, self.rolls[self.turn]):\n",
    "            # print(self.current_state)\n",
    "            self._add_message(response_text, role=\"assistant\")\n",
    "            for token in move.keys():\n",
    "                self.tokens_inplay[token] = move[token] > 0\n",
    "                self.current_position[token] = move[token]\n",
    "            self._update_board(move)\n",
    "            self.turn += 1\n",
    "            print(f\"TURN {self.turn}: {self.current_state}\")\n",
    "\n",
    "        # Otherwise, reports relevant information at the failing turn\n",
    "        else:\n",
    "            print(f\"Fail at turn {self.turn}\")\n",
    "            print(f\"Roll: {self.rolls[self.turn]}\")\n",
    "            print(f\"Move: {move}\")\n",
    "            print(response_text)\n",
    "            print(self.current_state)\n",
    "\n",
    "            # if self.reprompt:\n",
    "            #     self.make_move(self._reprompt(error_type=\"field number\"))\n",
    "\n",
    "    def _add_message(self, message: str, role: str = \"user\") -> None:\n",
    "        if not self.context:\n",
    "            self.context = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "            \n",
    "        self.context.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def _parse_reply(self, reply: str) -> dict:\n",
    "        matching_string: Match = re.search(r\"MY MOVE: X -> (\\d+) ; Y -> (\\d+)\", reply)\n",
    "\n",
    "        if not matching_string:\n",
    "            raise ValueError(\"Invalid response format\")\n",
    "\n",
    "        return {\"X\": int(matching_string.group(1)), \"Y\": int(matching_string.group(2))}\n",
    "\n",
    "    def _check_token_moved(self, move: dict) -> dict:\n",
    "        tokens_moved: dict = {}\n",
    "\n",
    "        for token in move.keys():\n",
    "            previous_location: int = self.current_position[token]\n",
    "            current_location: int = move[token]\n",
    "            tokens_moved[token] = previous_location != current_location\n",
    "\n",
    "        return tokens_moved\n",
    "\n",
    "    def _check_dual_token_moved(self, move: dict) -> bool:\n",
    "        tokens_moved: list = []\n",
    "\n",
    "        for token in move.keys():\n",
    "            tokens_moved.append(self.current_position[token] != move[token])\n",
    "\n",
    "        return True if all(tokens_moved) else False\n",
    "\n",
    "    def _find_selected(self, tokens_moved: dict) -> str:\n",
    "        for token in tokens_moved.keys():\n",
    "            if tokens_moved[token]:\n",
    "                selected: str = token\n",
    "\n",
    "        return selected\n",
    "\n",
    "    def _check_move(self, move: dict, roll: int) -> bool:\n",
    "        state: list = []\n",
    "\n",
    "        if self._check_dual_token_moved(move):\n",
    "            print(\"MOVE ERROR: Both in-play tokens were moved simultaneously.\")\n",
    "            return False\n",
    "\n",
    "        tokens_moved: dict = self._check_token_moved(move)\n",
    "        selected: str = self._find_selected(tokens_moved)\n",
    "\n",
    "        for token in move.keys():\n",
    "            match [selected, self.tokens_inplay[token]]:\n",
    "                \n",
    "                # if the token was not moved and has not been played to the board\n",
    "                case [False, False]: \n",
    "                    if roll != 6:\n",
    "                        state.append(True)\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(\"MOVE ERROR: A 6 was rolled but the selected out-of-play token was not played to the board.\")\n",
    "                        return False\n",
    "                \n",
    "                # if the token was not moved but has been played to the board\n",
    "                case [False, True]:\n",
    "                    if roll + self.current_position[token] > self.n_fields:\n",
    "                        state.append(True)\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(\"MOVE ERROR: The selected in-play token can be moved but was not.\")\n",
    "                        return False\n",
    "                \n",
    "                # if the selected token was moved\n",
    "                case [True, _]: \n",
    "                    match [token == selected]:\n",
    "                        \n",
    "                        # if the selected token has been moved\n",
    "                        case True: \n",
    "                            if roll == 6 and move[token] == 1:\n",
    "                                state.append(True)\n",
    "                                continue\n",
    "\n",
    "                            elif self.current_position[token] + roll == move[token]:\n",
    "                                state.append(True)\n",
    "                                continue\n",
    "\n",
    "                            else:\n",
    "                                print(\"MOVE ERROR: The selected token was not moved appropriately.\")\n",
    "                                return False\n",
    "\n",
    "                        # if the selected token has not been moved\n",
    "                        case False: \n",
    "                            state.append(True)\n",
    "                            continue\n",
    "                            \n",
    "        if all(state):\n",
    "            return True\n",
    "\n",
    "    def _reprompt(self, error_type: str) -> str:\n",
    "        match error_type:\n",
    "            case \"field number\":\n",
    "                return f\"There are 21 empty fields and 2 occupied fields. In total: 21 + 2 = 23 fields. Let's try again.\\n\"\n",
    "\n",
    "    def _update_board(self, move: dict) -> None:\n",
    "        split_board: list = self.board.split()\n",
    "        \n",
    "        for token in move.keys():\n",
    "            position: int = move[token]\n",
    "            if self.tokens_inplay[token]:\n",
    "                split_board[self.current_position[token] - 1] = \"□\"\n",
    "                split_board[position - 1] = token\n",
    "\n",
    "        self.current_state = \" \".join(split_board).rstrip()\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        self.turn = 0\n",
    "        self.context = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the LLM\n",
    "load_model_registry()\n",
    "THIS_MODEL = dict(model_id=\"gpt-3.5-turbo-1106\", backend=\"openai\", model_name = \"gpt-3.5-turbo-1106\")\n",
    "llm: Model = get_model_for(THIS_MODEL)\n",
    "llm.set_gen_args(temperature=0.0, max_tokens=400)\n",
    "\n",
    "# Loads the prompts\n",
    "with open('games/ludo/resources/initial_prompts/simple_prompt_v1.txt', 'r') as f:\n",
    "    system_prompt: str = f.read()\n",
    "with open('games/ludo/resources/prompts_pace/multitoken_v1.txt', 'r') as f:\n",
    "    instructions: str = f.read()\n",
    "\n",
    "# Defines the game instance\n",
    "instance: Game = Game(llm, system_prompt, instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURN 0: □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □\n",
      "TURN 1: X □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □\n",
      "TURN 2: □ □ □ □ □ X □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □ □\n",
      "TURN 3: □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □ □ □ □ □\n",
      "TURN 4: □ □ □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □\n",
      "TURN 5: Y □ □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □\n",
      "TURN 6: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\n",
      "MOVE ERROR: Both in-play tokens were moved simultaneously.\n",
      "Fail at turn 6\n",
      "Roll: 2\n",
      "Move: {'X': 13, 'Y': 3}\n",
      "There are 22 empty fields and 2 occupied fields. In total: 22 + 2 = 24 fields. I have token X on field 13 and token Y on field 1. You have rolled 2. This is 2 fields away from my previous position. Since both tokens are on the field, I can try to move any of them. I decide to move my token Y. Since 1 + 2 = 3, I need to move my token to field number 3.\n",
      "MY MOVE: X -> 13 ; Y -> 3\n",
      "Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\n",
      "2024-05-29 13:56:22,320 - backends.utils - WARNING - Found consecutive role assignments. These will be merged into one:\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n",
      "MOVE ERROR: Both in-play tokens were moved simultaneously.\n",
      "Fail at turn 6\n",
      "Roll: 2\n",
      "Move: {'X': 13, 'Y': 3}\n",
      "There are 22 empty fields and 2 occupied fields. In total: 22 + 2 = 24 fields. I have token X on field 13 and token Y on field 1. You have rolled 2. This is 2 fields away from my previous position. Since both tokens are on the field, I can try to move any of them. I decide to move my token Y. Since 1 + 2 = 3, I need to move my token to field number 3.\n",
      "MY MOVE: X -> 13 ; Y -> 3\n",
      "Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\n",
      "2024-05-29 13:56:24,364 - backends.utils - WARNING - Found consecutive role assignments. These will be merged into one:\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n",
      "2024-05-29 13:56:24,365 - backends.utils - WARNING - Found consecutive role assignments. These will be merged into one:\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\\n\\nCurrent state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n",
      "{'role': 'user', 'content': \"Current state: Y □ □ □ □ □ □ □ □ □ □ □ □ X □ □ □ □ □ □ □ □ □\\nNext turn number: 6, Roll: 2. Where will you move your token? Let's think step by step.\"}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid response format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36mGame.make_move\u001b[0;34m(self, reprompt_message)\u001b[0m\n\u001b[1;32m     44\u001b[0m _, _, response_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_response(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Parses and saves the response\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m move: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_text\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# If the move is valid, updates everything accordingly\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 82\u001b[0m, in \u001b[0;36mGame._parse_reply\u001b[0;34m(self, reply)\u001b[0m\n\u001b[1;32m     79\u001b[0m matching_string: Match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMY MOVE: X -> (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+) ; Y -> (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\"\u001b[39m, reply)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matching_string:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid response format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(matching_string\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(matching_string\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m))}\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid response format"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    instance.make_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instance.last_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "width, _ = shutil.get_terminal_size()\n",
    "\n",
    "for turn_content in instance.context:\n",
    "    print(\"=\" * width + \"\\n\")\n",
    "    print(f\"Role: {turn_content['role']}\")\n",
    "    print(turn_content[\"content\"] + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
