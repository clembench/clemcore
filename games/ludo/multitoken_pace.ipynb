{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "os.chdir(\"/Users/Pace/Documents/Education/Universität Potsdam/Semester 4 - Summer 2024/Evaluating Chatp-Optimized Language Models/Project\")\n",
    "from backends import ModelSpec, Model, get_model_for, load_model_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 34) (1455880178.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 34\u001b[0;36m\u001b[0m\n\u001b[0;31m    message += f\"\\nTurn number: {self.turn}, Roll: {self.rolls[self.turn]}.\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 34)\n"
     ]
    }
   ],
   "source": [
    "class Game:\n",
    "    \"\"\"\n",
    "    Class describing the behavior of the game of Ludo, used to prompt an LLM.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm: Model, system_prompt: str, instructions: str) -> None:\n",
    "        self.llm: Model = llm\n",
    "\n",
    "        # Prompt and response attributes\n",
    "        self.system_prompt: str = system_prompt\n",
    "        self.instructions: str = instructions\n",
    "        self.last_response: list = []\n",
    "        self.context: list = []\n",
    "        self.reprompt: bool = False\n",
    "\n",
    "        # Constructs board with n fields\n",
    "        self.n_fields: int = 23 # TODO Determine generative method for fields\n",
    "        cells: list = []\n",
    "        for _ in range(self.n_fields):\n",
    "            cells.append(\"□\")\n",
    "        self.board = \" \".join(cells).rstrip()\n",
    "        self.current_state: str = self.board\n",
    "\n",
    "        self.rolls: list = [6, 5, 4, 5, 6, 6, 2, 3, 6, 5, 1, 2, 5, 3, 4] # TODO Determine generative method for rolls\n",
    "        self.turn: int = 0\n",
    "\n",
    "        # Token attributes\n",
    "        self.tokens_inplay: dict = {\"X\": False, \"Y\": False}\n",
    "        self.current_position: dict = {\"X\": 0, \"Y\": 0}\n",
    "        self.six_count: int = 0\n",
    "\n",
    "    def make_move(self) -> None:\n",
    "        \"\"\"\n",
    "        When called, prompts the LLM according to the turn number, giving it the previous conversation \n",
    "        context, and requests its next move. The move is parsed, its validity is determined, at which point \n",
    "        either its move is reflected on the board or an error message is returned and the game ends.\n",
    "        \"\"\"\n",
    "        # Prepares the appropriate message for the current turn\n",
    "        match self.turn:\n",
    "            case 0:\n",
    "                print(f\"TURN 0: {self.board}\")\n",
    "                message: str = f\"{self.instructions}\\nAre you ready to play?\\nBeginning state: {self.board}\"\n",
    "                message += f\"\\nTurn number: {self.turn}, Roll: {self.rolls[self.turn]}. \"\n",
    "                message += \"Where will you move your token? Let's think step by step.\"\n",
    "\n",
    "            case _:\n",
    "                message: str = f\"Current state: {self.current_state}\"\n",
    "                message += f\"\\nNext turn number: {self.turn}, Roll: {self.rolls[self.turn]}. \"\n",
    "                message += \"Where will you move your token? Let's think step by step.\"\n",
    "\n",
    "        # Delivers the message, then retrieves the response\n",
    "        self._add_message(message)\n",
    "        _, _, response_text = self.llm.generate_response(self.context)\n",
    "\n",
    "        # Parses and saves the response\n",
    "        move: dict = self._parse_reply(response_text)\n",
    "        self.last_response = response_text\n",
    "\n",
    "        # If the move is valid, updates everything accordingly\n",
    "        if self._check_move(move, self.rolls[self.turn]):\n",
    "            self._add_message(response_text, role=\"assistant\")\n",
    "            for token in move.keys():\n",
    "                self.tokens_inplay[token] = move[token] > 0\n",
    "                self.current_position[token] = move[token]\n",
    "            self._update_board(move)\n",
    "            self.turn += 1\n",
    "            print(f\"TURN {self.turn}: {self.current_state}\")\n",
    "\n",
    "        # Otherwise, reports relevant information at the failing turn\n",
    "        else:\n",
    "            print(f\"Fail at turn {self.turn}\")\n",
    "            print(f\"Roll: {self.rolls[self.turn]}\")\n",
    "            print(f\"Move: {move}\")\n",
    "            print(response_text)\n",
    "            print(self.current_state)\n",
    "\n",
    "    def _add_message(self, message: str, role: str = \"user\") -> None:\n",
    "        \"\"\"\n",
    "        Adds a message to the conversation context. If the conversation has just begun and the context \n",
    "        is empty, we start by adding in the system prompt.\n",
    "\n",
    "        Args:\n",
    "            message (str): message to be added to the context\n",
    "            role (str): indicates to the LLM which role the message belongs to (i.e., 'system', \n",
    "                        'user', or 'assistant')\n",
    "        \"\"\"\n",
    "        if not self.context:\n",
    "            self.context = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "            \n",
    "        self.context.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def _parse_reply(self, reply: str) -> dict[str: int]:\n",
    "        \"\"\"\n",
    "        Parses the LLM's response according to a pre-described format, given in the instructions.\n",
    "\n",
    "        Args:\n",
    "            reply (str): the LLM's response to be parsed\n",
    "\n",
    "        Returns:\n",
    "            dict[str: int]: contains the LLM's move, described by the name of the token \n",
    "                            and the move destination\n",
    "\n",
    "        Raises:\n",
    "            ValueError: raised if the reply is not given in the described format\n",
    "        \"\"\"\n",
    "        matching_string: Match = re.search(r\"MY MOVE: X -> (\\d+) ; Y -> (\\d+)\", reply)\n",
    "\n",
    "        if not matching_string:\n",
    "            raise ValueError(\"Invalid response format\")\n",
    "\n",
    "        return {\"X\": int(matching_string.group(1)), \"Y\": int(matching_string.group(2))}\n",
    "\n",
    "    def _check_token_moved(self, move: dict[str: int]) -> dict[str: bool]:\n",
    "        \"\"\"\n",
    "        Determines if the LLM has decided to move the tokens (on a per-token basis).\n",
    "\n",
    "        Args:\n",
    "            move (dict[str: int]): contains the LLM's move, described by the name of the token\n",
    "                                   and the move destination\n",
    "\n",
    "        Returns:\n",
    "            dict[str: bool]: contains the name of the tokens and a bool, True if the token has \n",
    "                             been moved, False otherwise\n",
    "        \"\"\"\n",
    "        tokens_moved: dict = {}\n",
    "\n",
    "        for token in move.keys():\n",
    "            tokens_moved[token] = self.current_position[token] != move[token]\n",
    "\n",
    "        return tokens_moved\n",
    "\n",
    "    def _check_both_tokens_moved(self, move: dict[str: int]) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if the LLM has decided to move both of its tokens in one turn.\n",
    "\n",
    "        Args:\n",
    "            move (dict[str: int]): contains the LLM's move, described by the name of the token\n",
    "                                   and the move destination\n",
    "\n",
    "        Returns:\n",
    "            bool: True if both tokens were moved, False otherwise\n",
    "        \"\"\"\n",
    "        return True if all([value for value in _check_token_moved(move).values()]) else False\n",
    "\n",
    "    def _find_selected(self, tokens_moved: dict[str: bool]) -> str:\n",
    "        \"\"\"\n",
    "        If a token was moved during a turn, determines which token was moved.\n",
    "\n",
    "        Args:\n",
    "            tokens_moved (dict[str: bool]): contains the name of the tokens and a bool, True if \n",
    "                                            the token has been moved, False otherwise\n",
    "\n",
    "        Returns:\n",
    "            str: name of the token which was moved during the turn\n",
    "        \"\"\"\n",
    "        for token in tokens_moved.keys():\n",
    "            if tokens_moved[token]:\n",
    "                selected: str = token\n",
    "\n",
    "        return selected\n",
    "\n",
    "    def _check_move(self, move: dict[str: int], roll: int) -> bool:\n",
    "        \"\"\"\n",
    "        Determines if a given move is legal, according to the game's rules and the die roll \n",
    "        given during the turn.\n",
    "        \n",
    "        Args:\n",
    "            move (dict[str: int]): contains the LLM's move, described by the name of the token \n",
    "                                   and the move destination\n",
    "            roll (int): the die roll for the turn\n",
    "\n",
    "        Returns:\n",
    "            bool: True if a move is valid, False otherwise\n",
    "        \"\"\"\n",
    "        if self._check_both_tokens_moved(move):\n",
    "            print(\"MOVE ERROR: Both in-play tokens were moved simultaneously.\")\n",
    "            return False\n",
    "\n",
    "        state: list = []\n",
    "        selected: str = self._find_selected(self._check_token_moved(move))\n",
    "\n",
    "        for token in move.keys():\n",
    "            match [selected, self.tokens_inplay[token]]:\n",
    "                \n",
    "                # if the token was not moved and has not been played to the board\n",
    "                case [False, False]: \n",
    "                    if roll != 6:\n",
    "                        state.append(True)\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(f\"MOVE ERROR: A 6 was rolled but the token {token} was not played to the board.\")\n",
    "                        return False\n",
    "                \n",
    "                # if the token was not moved but has been played to the board\n",
    "                case [False, True]:\n",
    "                    if roll + self.current_position[token] > self.n_fields:\n",
    "                        state.append(True)\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(f\"MOVE ERROR: The token {token} can be moved but was not.\")\n",
    "                        return False\n",
    "                \n",
    "                # if the selected token was moved\n",
    "                case [True, _]: \n",
    "                    match [token == selected]:\n",
    "                        \n",
    "                        # if the selected token has been moved\n",
    "                        case True: \n",
    "                            if roll == 6 and move[token] == 1:\n",
    "                                state.append(True)\n",
    "                                continue\n",
    "\n",
    "                            elif self.current_position[token] + roll == move[token]:\n",
    "                                state.append(True)\n",
    "                                continue\n",
    "\n",
    "                            else:\n",
    "                                print(f\"MOVE ERROR: The token {token} was not moved appropriately.\")\n",
    "                                return False\n",
    "\n",
    "                        # if the selected token has not been moved\n",
    "                        case False: \n",
    "                            state.append(True)\n",
    "                            continue\n",
    "                            \n",
    "        if all(state):\n",
    "            return True\n",
    "\n",
    "    # TODO Build reprompt functionality\n",
    "    def _reprompt(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def _update_board(self, move: dict[str: int]) -> None:\n",
    "        \"\"\"\n",
    "        Updates the current state of the board given a valid move.\n",
    "\n",
    "        Args:\n",
    "            move (dict[str: int]): contains the LLM's move, described by the name of the token \n",
    "                                   and the move destination\n",
    "        \"\"\"\n",
    "        split_board: list = self.board.split()\n",
    "        \n",
    "        for token in move.keys():\n",
    "            position: int = move[token]\n",
    "            if self.tokens_inplay[token]:\n",
    "                split_board[self.current_position[token] - 1] = \"□\"\n",
    "                split_board[position - 1] = token\n",
    "\n",
    "        self.current_state = \" \".join(split_board).rstrip()\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        self.turn = 0\n",
    "        self.context = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the LLM\n",
    "load_model_registry()\n",
    "THIS_MODEL = dict(model_id=\"gpt-3.5-turbo-1106\", backend=\"openai\", model_name = \"gpt-3.5-turbo-1106\")\n",
    "llm: Model = get_model_for(THIS_MODEL)\n",
    "llm.set_gen_args(temperature=0.0, max_tokens=400)\n",
    "\n",
    "# Loads the prompts\n",
    "with open('games/ludo/resources/initial_prompts/simple_prompt_v1.txt', 'r') as f:\n",
    "    system_prompt: str = f.read()\n",
    "with open('games/ludo/resources/prompts_pace/multitoken_v1.txt', 'r') as f:\n",
    "    instructions: str = f.read()\n",
    "\n",
    "# Defines the game instance\n",
    "instance: Game = Game(llm, system_prompt, instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    instance.make_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instance.last_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "width, _ = shutil.get_terminal_size()\n",
    "\n",
    "for turn_content in instance.context:\n",
    "    print(\"=\" * width + \"\\n\")\n",
    "    print(f\"Role: {turn_content['role']}\")\n",
    "    print(turn_content[\"content\"] + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
